{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLyYEVvfyw9q",
        "outputId": "a9be53bb-d86c-4abf-c547-36b1c5885c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftPlyanuak8n",
        "outputId": "47842259-8111-4011-b8f6-846fadac7d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "print(newsgroups_train.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "5c97a2ed-f776-47b6-bb1c-8cb524d74abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "Cantidad de documentos: 11314\n",
            "Tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'Cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'Tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "a50886a5-7f16-40f8-a447-528402ad9de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "2f0e128d-2d30-441a-d3bd-74afb63a2956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "4ec37caf-2152-469a-d08a-6090001af42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "6590f9cf-48ab-418e-f650-cc62a35a62e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "7e566e00-7c8c-4ee4-ec49-0a553f3d054b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "19aac878-f07c-47f9-b7ab-629da97ebdf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4811, 6635, 4253, ..., 9019, 9016, 8748])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QdJLHPJACvaj",
        "outputId": "80da6d00-e9bf-4fa5-e2e8-9f67bcd22eeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "d190c608-17fb-437c-cdaa-c3699ad3ffe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TPM0thDaLk0R",
        "outputId": "ee9fdf8c-3e3c-4f42-ff0d-55af9f4ecc76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "d755dd63-d28e-4eaf-e513-5b2796e4409d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**Cada experimento realizado debe estar acompañado de una explicación o interpretación de lo observado.**\n",
        "\n",
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.\n",
        "\n",
        "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**NO cambiar el hiperparámetro ngram_range de los vectorizadores**.\n",
        "\n",
        "**4**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.\n",
        "\n",
        "**Elegir las palabras MANUALMENTE para evitar la aparición de términos poco interpretables**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESOLUCIÓN DESAFÍO 1**"
      ],
      "metadata": {
        "id": "Ur9qzQUzXPtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Similaridad entre documentos (5 documentos al azar)\n",
        "\n",
        "En este experimento seleccionamos 5 documentos al azar del conjunto de entrenamiento, los vectorizamos con TF–IDF (ya calculado en `X_train`) y medimos la similaridad coseno con todos los demás documentos de entrenamiento.\n",
        "\n",
        "Para cada documento base analizamos los 5 documentos más similares y comparamos:\n",
        "\n",
        "- El **contenido textual** (temática, palabras clave).\n",
        "- La **etiqueta de clase** (`target_names`).\n",
        "\n",
        "De esta forma evaluamos si la similaridad en el espacio TF–IDF refleja una proximidad semántica razonable entre los documentos.\n",
        "Code"
      ],
      "metadata": {
        "id": "V1jYR_ymXjkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fijamos semilla para reproducibilidad\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "# Cantidad de documentos en entrenamiento\n",
        "n_docs_train = X_train.shape[0]\n",
        "\n",
        "# Elegimos 5 documentos al azar del conjunto de entrenamiento\n",
        "random_indices = rng.choice(n_docs_train, size=5, replace=False)\n",
        "random_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGjqvq0EXLHX",
        "outputId": "8bb2091d-7ca3-4687-db66-150303df8532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7492, 3546, 5582, 4793, 3813])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para cada uno de esos 5 documentos calculamos la similaridad coseno\n",
        "# con TODOS los documentos de entrenamiento y mostramos los 5 más similares\n",
        "\n",
        "for idx in random_indices:\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"Documento base índice {idx}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(newsgroups_train.data[idx][:700].replace(\"\\n\", \" \") + \"...\")\n",
        "    print()\n",
        "    print(f\"Clase del documento base: {newsgroups_train.target_names[y_train[idx]]}\")\n",
        "\n",
        "    # similaridad coseno con todos los docs de train\n",
        "    cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "    # índices ordenados de mayor a menor similaridad\n",
        "    ordered = np.argsort(cossim)[::-1]\n",
        "\n",
        "    # descartamos el propio documento (ordered[0]) y tomamos los 5 siguientes\n",
        "    most_similar = ordered[1:6]\n",
        "\n",
        "    print(\"\\nÍndices de los 5 documentos más similares:\", most_similar)\n",
        "    print(\"Similaridades:\", cossim[most_similar])\n",
        "    print(\"\\nClases de los 5 documentos más similares:\")\n",
        "    for i in most_similar:\n",
        "        print(f\"  idx {i:5d}  ->  {newsgroups_train.target_names[y_train[i]]}\")\n",
        "\n",
        "    print(\"\\nPequeño snippet de los documentos más similares:\\n\")\n",
        "    for i in most_similar:\n",
        "        snippet = newsgroups_train.data[i][:300].replace(\"\\n\", \" \")\n",
        "        print(f\"[idx {i}] {snippet}...\")\n",
        "        print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VURfLs3QXmUX",
        "outputId": "fa8f83d9-3e26-41bd-f493-6387c5999654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Documento base índice 7492\n",
            "------------------------------------------------------------\n",
            "Could someone please post any info on these systems.  Thanks. BoB --  ----------------------------------------------------------------------  Robert Novitskey | \"Pursuing women is similar to banging one's head rrn@po.cwru.edu  |  against a wall...with less opportunity for reward\" ...\n",
            "\n",
            "Clase del documento base: comp.sys.mac.hardware\n",
            "\n",
            "Índices de los 5 documentos más similares: [10935  7258  4971  4303   645]\n",
            "Similaridades: [0.66652622 0.34759576 0.17986167 0.15465159 0.14143451]\n",
            "\n",
            "Clases de los 5 documentos más similares:\n",
            "  idx 10935  ->  comp.sys.mac.hardware\n",
            "  idx  7258  ->  comp.sys.ibm.pc.hardware\n",
            "  idx  4971  ->  comp.sys.mac.hardware\n",
            "  idx  4303  ->  misc.forsale\n",
            "  idx   645  ->  comp.sys.mac.hardware\n",
            "\n",
            "Pequeño snippet de los documentos más similares:\n",
            "\n",
            "[idx 10935] Hey everybody:     I want to buy a mac and I want to get a good price...who doesn't?  So, could anyone out there who has found a really good deal on a Centris 650 send me the price.  I don't want to know where, unless it is mail order or areound cleveland, Ohio.  Also, should I buy now or wait for t...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 7258] Hay all:      Has anyone out there heard of any performance stats on the fabled p24t.  I was wondering what it's performance compared to the 486/66 and/or pentium would be.  Any info would be helpful.  Later BoB --  Robert Novitskey | rrn@po.cwru.edu | (216)754-2134 | CWRU Cleve. Ohio --------------...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4971] Could someone please send instructions for installing simms and vram to  jmk13@po.cwru.edu?  He's just gotten his 700 and wants to drop in some  extra simms and vram that he has for it....\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4303] For sale:  Roland D-50: $700 or best offer. Excellent condition. Includes over 1000 patches on disk (In cakewalk sysex format)  Buyer must pay COD shipping.  Please e-mail responses to: gms2@po.cwru.edu  Thanks.  George ...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 645] I'd appreciate it greatly if someone could E-mail me the following: (if you only know one, that's fine) 1) Specs for the 68040 (esp. how it compares to the Pentium) 2) Specs for the 68060 with estimated cost, release date, etc...  I'm interested in speeds, systems it can run (Windows NT, RISC, or wh...\n",
            "--------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Documento base índice 3546\n",
            "------------------------------------------------------------\n",
            "       Don't bother if you have CPBackup or Fastback.  They all offer options  not available in the stripped-down MS version (FROM CPS!).  Examples - no  proprietary format (to save space), probably no direct DMA access, and no  tape drive!...\n",
            "\n",
            "Clase del documento base: comp.os.ms-windows.misc\n",
            "\n",
            "Índices de los 5 documentos más similares: [5665 2011 8643 1546 8765]\n",
            "Similaridades: [0.20404926 0.19242984 0.17241547 0.17092173 0.16161396]\n",
            "\n",
            "Clases de los 5 documentos más similares:\n",
            "  idx  5665  ->  comp.sys.ibm.pc.hardware\n",
            "  idx  2011  ->  comp.sys.ibm.pc.hardware\n",
            "  idx  8643  ->  comp.sys.ibm.pc.hardware\n",
            "  idx  1546  ->  comp.sys.ibm.pc.hardware\n",
            "  idx  8765  ->  comp.sys.ibm.pc.hardware\n",
            "\n",
            "Pequeño snippet de los documentos más similares:\n",
            "\n",
            "[idx 5665]  By initiating a DMA xfer.  :)  Seriously, busmastering adapter have their own DMA ability, they don't use the motherboards on-board DMA(which is *MUCH* slower).  ISA has no bus arbitration, so if two busmastering cards in 1 ISA system try to do DMA xfers on the same DMA channel the system will lock...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 2011]   IDE also uses DMA techniques.  I believe floppy controller also uses DMA, and most A/D boards also use DMA.  DMA is no big deal, and has nothing to do directly with SCSI.   You can thank your software for that.  If DOS had a few more brains, it could format floppies etc. while you were doing somet...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 8643]  There would be no problems as long as the OS didn't set up a DMA transfer to an area above the 16 mb area (the DMA controller probably can't be programmed that way anyways, so there probably isin't a problem with this)...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 1546]        Here's a document that I wrote some time back.  It's slightly out-of-date, now that DOS 6 has been released, but much of it is still useful.       -- Darryl Okahata \tInternet: darrylo@sr.hp.com  DISCLAIMER: this message is the author's personal opinion and does not constitute the support, opi...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 8765] The floppy is served by DMA on the motherboard, and original DMA-controller can't reach more than the first 16MB (The address-space of the ISA-bus) joerg ...\n",
            "--------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Documento base índice 5582\n",
            "------------------------------------------------------------\n",
            "5.25\" Internal Low density disk drive.  Monochrome monitor  8088 motherboard, built in parallel and serial ports, built in mono and color output, 7Mhz.  Libertarian, atheist, semi-anarchal Techno-Rat....\n",
            "\n",
            "Clase del documento base: misc.forsale\n",
            "\n",
            "Índices de los 5 documentos más similares: [5510 4922 4347 8057 4028]\n",
            "Similaridades: [0.46224367 0.29985306 0.27401734 0.20757132 0.16852062]\n",
            "\n",
            "Clases de los 5 documentos más similares:\n",
            "  idx  5510  ->  misc.forsale\n",
            "  idx  4922  ->  misc.forsale\n",
            "  idx  4347  ->  comp.graphics\n",
            "  idx  8057  ->  misc.forsale\n",
            "  idx  4028  ->  comp.graphics\n",
            "\n",
            "Pequeño snippet de los documentos más similares:\n",
            "\n",
            "[idx 5510] I am looking for a 286 motherboard, preferable 12 or 16, 640k or 1 meg RAM.  I am also looking for a VGA card.  Am willing to trade 1200 external, 5.25\" LD Drive, 8088 motherboard, monochrome monitor, Game Boy, in some combination for the above.  Libertarian, atheist, semi-anarchal Techno-Rat....\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4922] For sale:  Nintendo Game Boy, Tetris, Castlevania Adventure, All-Star Challenge, Nemesis, Play-Action football, link cable.  Make me an offer.  Libertarian, atheist, semi-anarchal Techno-Rat....\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4347]   It's really not that hard to do.  There are books out there which explain everything, and the basic 3D functions, translation, rotation, shading, and hidden line removal are pretty easy.  I wrote a program in a few weeks witht he help of a book, and would be happy to give you my source. \tAlso, Qui...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 8057] Hello, I have a motherboard and a case for sale as a package. Both of them came from a CompuAdd computer I bought last August and am    presently upgrading. Here are the specs--  Motherboard ----------- Cyrix 486SL 25 MHz microprocessor Chips and Technology chipset (SCATsx V2.3.6 SLSLC) 8 SIMM banks...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4028] Hello, and thank you for reading this request.  I have a Mpeg viewer for x-windows and it did not run because I was running it on a monochrome monitor.  I need the mono-driver for mpeg_play.   ...\n",
            "--------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Documento base índice 4793\n",
            "------------------------------------------------------------\n",
            "Hi,  In Canada, any gun that enters a National Park must be sealed (I think it's a small metal tag that's placed over the trigger).  The net result of this is that you _can't_ use a gun to protect yourself from bears (or psychos) in the National Parks.  Instead, one has to be sensitive to the dangers and annoyances of hiking in bear country, and take the appropriate precautions.  I think this policy makes the users of the National Parks feel a little closer to Nature, that they are a part of Nature and, as such, have to deal with nature on it's own terms....\n",
            "\n",
            "Clase del documento base: talk.politics.guns\n",
            "\n",
            "Índices de los 5 documentos más similares: [ 6894  5856  4271  3141 10836]\n",
            "Similaridades: [0.23640976 0.23625331 0.23284283 0.22954088 0.22905088]\n",
            "\n",
            "Clases de los 5 documentos más similares:\n",
            "  idx  6894  ->  talk.politics.guns\n",
            "  idx  5856  ->  sci.crypt\n",
            "  idx  4271  ->  talk.politics.misc\n",
            "  idx  3141  ->  talk.politics.guns\n",
            "  idx 10836  ->  alt.atheism\n",
            "\n",
            "Pequeño snippet de los documentos más similares:\n",
            "\n",
            "[idx 6894] Here is a press release from the White House.   President Clinton's Remarks On Waco With Q/A  To: National Desk  Contact: White House Office of the Press Secretary, 202-456-2100     WASHINGTON, April 20 -- Following are remarks by President  Clinton in a question and answer session with the press:  ...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 5856]  Thanks for posting this and making it available. This post will be LONG, I will comment on most of it, and am reluctantly leaving all of the original in place to provide context.  Please note that an alt. group has been set up for the Clipper stuff.                                                  ...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 4271] THE WHITE HOUSE                      Office of the Press Secretary ______________________________________________________________ For Immediate Release                             April 13, 1993       \t                            REMARKS BY THE PRESIDENT,                SECRETARY OF EDUCATION RICHAR...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 3141]         Mr. Parsli, I have to take exception at this.  There are verifiable, previous *examples* of levels of U.S. governments abusing gun-control restrictions.  I don't think it is paranoid to worry that what has been abused in the recent past might be abused in thye future.  After so many times of...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 10836] Archive-name: atheism/faq Alt-atheism-archive-name: faq Last-modified: 5 April 1993 Version: 1.1                      Alt.Atheism Frequently-Asked Questions  This file contains responses to articles which occur repeatedly in alt.atheism.  Points covered here are ones which are not covered in the \"In...\n",
            "--------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Documento base índice 3813\n",
            "------------------------------------------------------------\n",
            " Doesn't it also have the Statue of Liberty on it or is that Richter's Mask?  The back actually has a Bee followed by a Z to represent the Beezer. It  also has something that looks like the three interconnecting circles from the Led Zepplin 4 album cover. Is that what it is supposed to be? and if it is does anybody know why he would put it there? Ali?   John \"The official Language of Golf is Profanity\"   ...\n",
            "\n",
            "Clase del documento base: rec.sport.hockey\n",
            "\n",
            "Índices de los 5 documentos más similares: [10836   759   913  5826  5856]\n",
            "Similaridades: [0.25139291 0.24798043 0.24095812 0.24094571 0.23294089]\n",
            "\n",
            "Clases de los 5 documentos más similares:\n",
            "  idx 10836  ->  alt.atheism\n",
            "  idx   759  ->  soc.religion.christian\n",
            "  idx   913  ->  alt.atheism\n",
            "  idx  5826  ->  soc.religion.christian\n",
            "  idx  5856  ->  sci.crypt\n",
            "\n",
            "Pequeño snippet de los documentos más similares:\n",
            "\n",
            "[idx 10836] Archive-name: atheism/faq Alt-atheism-archive-name: faq Last-modified: 5 April 1993 Version: 1.1                      Alt.Atheism Frequently-Asked Questions  This file contains responses to articles which occur repeatedly in alt.atheism.  Points covered here are ones which are not covered in the \"In...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 759]  Oh contrer mon captitan!  There is a way.  Certainly it is not by human reason.  Certainly it is not by human experience. (and yet it is both!)  To paraphrase Sartre, the particular is absurd unless it has an infinite reference point.  It is only because of God's own revelation that we can be absol...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 913] The recent rise of nostalgia in this group, combined with the   incredible level of utter bullshit, has prompted me to comb   through my archives and pull out some of \"The Best of Alt.Atheism\"   for your reading pleasure.  I'll post a couple of these a day   unless group concensus demands that I sto...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 5826] A listmember (D Andrew Killie, I think) wrote, in response to the suggestion that genocide may sometimes be the will of God:   > Any God who works that way is indescribably evil,  > and unworthy of my worship or faith.  Nobuya \"Higgy\" Higashiyama replied (as, in substance, did others):   > Where is ...\n",
            "--------------------------------------------------------------------------------\n",
            "[idx 5856]  Thanks for posting this and making it available. This post will be LONG, I will comment on most of it, and am reluctantly leaving all of the original in place to provide context.  Please note that an alt. group has been set up for the Clipper stuff.                                                  ...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Clasificación por prototipos (1-NN con similaridad coseno)\n",
        "\n",
        "En este experimento construimos un clasificador tipo “prototipos”:\n",
        "\n",
        "- Cada documento de test se vectoriza con el mismo TF–IDF (ya disponible en `X_test`).\n",
        "- Calculamos la similaridad coseno con **todos** los documentos de entrenamiento (`X_train`).\n",
        "- Asignamos la clase del documento de entrenamiento **más similar** (1-nearest neighbor).\n",
        "\n",
        "Luego medimos el desempeño usando F1-score macro sobre el conjunto de test y lo comparamos con los modelos de Naïve Bayes.\n"
      ],
      "metadata": {
        "id": "X_6lAPfDXrnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clasificador \"por prototipos\": para cada doc de test buscamos el doc de train\n",
        "# más similar (1-NN con similaridad coseno).\n",
        "\n",
        "batch_size = 300   # procesamos en batches para no explotar memoria\n",
        "n_test = X_test.shape[0]\n",
        "\n",
        "y_pred_proto = np.empty_like(y_test)\n",
        "\n",
        "for start in range(0, n_test, batch_size):\n",
        "    end = min(start + batch_size, n_test)\n",
        "\n",
        "    # similaridad coseno entre los docs de test del batch y TODOS los de train\n",
        "    sims = cosine_similarity(X_test[start:end], X_train)   # shape: (batch_size, n_train)\n",
        "\n",
        "    # índice del doc de train más similar para cada doc de test del batch\n",
        "    best_idx = sims.argmax(axis=1)\n",
        "\n",
        "    # asignamos la clase correspondiente\n",
        "    y_pred_proto[start:end] = y_train[best_idx]\n",
        "\n",
        "# Métrica F1 macro del clasificador por prototipos\n",
        "f1_proto = f1_score(y_test, y_pred_proto, average=\"macro\")\n",
        "print(f\"F1 macro en test (clasificador por prototipos 1-NN): {f1_proto:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xg9foH1XopP",
        "outputId": "edb77af5-aa31-461c-b969-b3ddf1b5ea3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 macro en test (clasificador por prototipos 1-NN): 0.5050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Naïve Bayes Multinomial y ComplementNB con búsqueda de hiperparámetros\n",
        "\n",
        "En esta sección entrenamos dos modelos Naïve Bayes:\n",
        "\n",
        "1. `MultinomialNB`\n",
        "2. `ComplementNB`\n",
        "\n",
        "Ambos con un `TfidfVectorizer` (sin cambiar el hiperparámetro `ngram_range`), y ajustamos hiperparámetros con `GridSearchCV`:\n",
        "\n",
        "- `tfidfvect__max_df`\n",
        "- `tfidfvect__min_df`\n",
        "- `tfidfvect__sublinear_tf`\n",
        "- `clf__alpha`\n",
        "\n",
        "La métrica utilizada es F1-score macro y se emplea validación cruzada con `cv=3`."
      ],
      "metadata": {
        "id": "TOAt3TTrX57g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Pipeline con TF-IDF + MultinomialNB\n",
        "pipe_mnb = Pipeline([\n",
        "    (\"tfidfvect\", TfidfVectorizer()),   # ngram_range por defecto (1,1) -> NO lo cambiamos\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Grid de hiperparámetros (moderado para no tardar una eternidad)\n",
        "param_grid_mnb = {\n",
        "    \"tfidfvect__max_df\": [0.9, 0.95],\n",
        "    \"tfidfvect__min_df\": [2, 5],\n",
        "    \"tfidfvect__sublinear_tf\": [True, False],\n",
        "    \"clf__alpha\": [0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid_mnb = GridSearchCV(\n",
        "    pipe_mnb,\n",
        "    param_grid=param_grid_mnb,\n",
        "    scoring=\"f1_macro\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_mnb.fit(newsgroups_train.data, y_train)\n",
        "\n",
        "print(\"Mejores hiperparámetros MultinomialNB:\")\n",
        "print(grid_mnb.best_params_)\n",
        "\n",
        "best_mnb = grid_mnb.best_estimator_\n",
        "y_pred_mnb = best_mnb.predict(newsgroups_test.data)\n",
        "f1_mnb = f1_score(y_test, y_pred_mnb, average=\"macro\")\n",
        "print(f\"F1 macro en test (MultinomialNB): {f1_mnb:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpoMGs60XyXf",
        "outputId": "91657dd6-8e5a-4e6e-a41a-3aff46ecec9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Mejores hiperparámetros MultinomialNB:\n",
            "{'clf__alpha': 0.1, 'tfidfvect__max_df': 0.9, 'tfidfvect__min_df': 2, 'tfidfvect__sublinear_tf': False}\n",
            "F1 macro en test (MultinomialNB): 0.6727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con TF-IDF + ComplementNB\n",
        "pipe_cnb = Pipeline([\n",
        "    (\"tfidfvect\", TfidfVectorizer()),   # ngram_range=(1,1) por defecto\n",
        "    (\"clf\", ComplementNB())\n",
        "])\n",
        "\n",
        "param_grid_cnb = {\n",
        "    \"tfidfvect__max_df\": [0.9, 0.95],\n",
        "    \"tfidfvect__min_df\": [2, 5],\n",
        "    \"tfidfvect__sublinear_tf\": [True, False],\n",
        "    \"clf__alpha\": [0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid_cnb = GridSearchCV(\n",
        "    pipe_cnb,\n",
        "    param_grid=param_grid_cnb,\n",
        "    scoring=\"f1_macro\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_cnb.fit(newsgroups_train.data, y_train)\n",
        "\n",
        "print(\"Mejores hiperparámetros ComplementNB:\")\n",
        "print(grid_cnb.best_params_)\n",
        "\n",
        "best_cnb = grid_cnb.best_estimator_\n",
        "y_pred_cnb = best_cnb.predict(newsgroups_test.data)\n",
        "f1_cnb = f1_score(y_test, y_pred_cnb, average=\"macro\")\n",
        "print(f\"F1 macro en test (ComplementNB): {f1_cnb:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORmOnVwnYEq_",
        "outputId": "ac3e3085-27ec-493a-88c7-fd27896842d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Mejores hiperparámetros ComplementNB:\n",
            "{'clf__alpha': 0.5, 'tfidfvect__max_df': 0.9, 'tfidfvect__min_df': 2, 'tfidfvect__sublinear_tf': True}\n",
            "F1 macro en test (ComplementNB): 0.6964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados obtenidos fueron aproximadamente:\n",
        "\n",
        "- F1 macro MultinomialNB: **0.6727**\n",
        "- F1 macro ComplementNB: **0.6964**\n",
        "\n",
        "En este experimento se observa que (completar según resultados):\n",
        "\n",
        "- El modelo ComplementNB tiende a mejorar el F1 macro en comparación con MultinomialNB, especialmente si el dataset está desbalanceado.\n",
        "- El ajuste de `min_df` y `max_df` permite filtrar términos demasiado raros o demasiado frecuentes, mejorando la capacidad del modelo para generalizar.\n",
        "- El parámetro `alpha` controla la suavización: valores intermedios (0.5–1.0) suelen evitar sobreajuste y mejorar la estabilidad del modelo.\n"
      ],
      "metadata": {
        "id": "vSMYHVLTYLNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Similaridad entre palabras a partir de la matriz término–documento\n",
        "\n",
        "Transponiendo la matriz documento–término `X_train` obtenemos una matriz término–documento, donde:\n",
        "\n",
        "- Cada **palabra** queda representada por un vector que indica en qué documentos aparece y con qué peso TF–IDF.\n",
        "- La similaridad coseno entre estos vectores nos permite medir qué palabras tienden a aparecer en contextos similares.\n",
        "\n",
        "Se seleccionan manualmente 5 palabras interpretables y, para cada una, se buscan las 5 palabras más similares.\n"
      ],
      "metadata": {
        "id": "8KaUK5HUYQFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz término-documento: transpuesta de la matriz documento-término\n",
        "X_terms = X_train.T   # shape: (n_terms, n_docs)\n",
        "X_terms.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UCw6Hb6YMBP",
        "outputId": "cd2a34cd-4ea7-4755-ca65-3359906570e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101631, 11314)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_words = [\"space\", \"nasa\", \"windows\", \"hockey\", \"jesus\"]\n",
        "\n",
        "for w in selected_words:\n",
        "    if w not in tfidfvect.vocabulary_:\n",
        "        print(f\"La palabra '{w}' NO está en el vocabulario, elegí otra.\")\n"
      ],
      "metadata": {
        "id": "1r4ner0lYSUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in selected_words:\n",
        "    if w not in tfidfvect.vocabulary_:\n",
        "        continue  # saltamos las que no estén\n",
        "\n",
        "    term_idx = tfidfvect.vocabulary_[w]\n",
        "\n",
        "    # vector de la palabra w (en el espacio de documentos)\n",
        "    term_vec = X_terms[term_idx]\n",
        "\n",
        "    # similaridad coseno con todas las demás palabras\n",
        "    cossim_terms = cosine_similarity(term_vec, X_terms)[0]  # (n_terms,)\n",
        "\n",
        "    # ordenamos de mayor a menor similaridad\n",
        "    ordered_terms = np.argsort(cossim_terms)[::-1]\n",
        "\n",
        "    # descartamos la propia palabra (índice term_idx)\n",
        "    ordered_terms = [i for i in ordered_terms if i != term_idx]\n",
        "\n",
        "    # tomamos las 5 más similares\n",
        "    most_similar_terms = ordered_terms[:5]\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Palabra base: '{w}'\")\n",
        "    print(\"5 palabras más similares según TF–IDF:\")\n",
        "    for i in most_similar_terms:\n",
        "        similar_word = idx2word[i]\n",
        "        sim_val = cossim_terms[i]\n",
        "        print(f\"  {similar_word:20s}  (similaridad coseno = {sim_val:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TGz1JSCYUc_",
        "outputId": "f51684be-9af2-4cf5-a6da-fb712133a266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Palabra base: 'space'\n",
            "5 palabras más similares según TF–IDF:\n",
            "  nasa                  (similaridad coseno = 0.3304)\n",
            "  seds                  (similaridad coseno = 0.2966)\n",
            "  shuttle               (similaridad coseno = 0.2928)\n",
            "  enfant                (similaridad coseno = 0.2803)\n",
            "  seti                  (similaridad coseno = 0.2465)\n",
            "================================================================================\n",
            "Palabra base: 'nasa'\n",
            "5 palabras más similares según TF–IDF:\n",
            "  gov                   (similaridad coseno = 0.4250)\n",
            "  44135                 (similaridad coseno = 0.3613)\n",
            "  433                   (similaridad coseno = 0.3517)\n",
            "  lerc                  (similaridad coseno = 0.3419)\n",
            "  larc                  (similaridad coseno = 0.3361)\n",
            "================================================================================\n",
            "Palabra base: 'windows'\n",
            "5 palabras más similares según TF–IDF:\n",
            "  dos                   (similaridad coseno = 0.3037)\n",
            "  ms                    (similaridad coseno = 0.2320)\n",
            "  microsoft             (similaridad coseno = 0.2219)\n",
            "  nt                    (similaridad coseno = 0.2140)\n",
            "  for                   (similaridad coseno = 0.1930)\n",
            "================================================================================\n",
            "Palabra base: 'hockey'\n",
            "5 palabras más similares según TF–IDF:\n",
            "  ncaa                  (similaridad coseno = 0.2743)\n",
            "  nhl                   (similaridad coseno = 0.2653)\n",
            "  affiliates            (similaridad coseno = 0.2480)\n",
            "  xenophobes            (similaridad coseno = 0.2426)\n",
            "  sportschannel         (similaridad coseno = 0.2228)\n",
            "================================================================================\n",
            "Palabra base: 'jesus'\n",
            "5 palabras más similares según TF–IDF:\n",
            "  christ                (similaridad coseno = 0.3039)\n",
            "  god                   (similaridad coseno = 0.2688)\n",
            "  kingdom               (similaridad coseno = 0.2130)\n",
            "  mat                   (similaridad coseno = 0.1967)\n",
            "  bible                 (similaridad coseno = 0.1951)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comentarios sobre cada experimentos planteado**:\n",
        "\n",
        "**1. Similaridad entre documentos (TF-IDF + 5 documentos elegidos al azar)**\n",
        "\n",
        "**Observaciones**\n",
        "\n",
        "Para cada uno de los 5 documentos seleccionados, los 5 documentos más similares según la métrica de coseno suelen pertenecer a la misma etiqueta de clasificación o a categorías temáticamente próximas.\n",
        "La similaridad entre documentos también revela casos de solapamientos temáticos entre ciertas categorías del dataset (p. ej., política y religión, tecnología y ciencia), lo que justifica errores típicos de clasificación.\n",
        "La vectorización TF-IDF capta suficientemente bien las relaciones lexicográficas para que los documentos más cercanos reflejen, en la mayoría de los casos, similitud semántica.\n",
        "El análisis permite validar empíricamente que el dataset tiene una estructura interna coherente: documentos con temas similares efectivamente comparten términos relevantes que TF-IDF realza.\n",
        "Los casos donde no hubo correspondencia entre similaridad y etiqueta pueden deberse a ruido y/o ambigüedad, lo cual influye en los modelos posteriores.\n",
        "\n",
        "**2. Clasificación zero-shot por prototipos (similaridad contra el training)**\n",
        "\n",
        "**Observaciones**\n",
        "\n",
        "El modelo asigna clases únicamente en función del documento del conjunto de entrenamiento más similar.\n",
        "Se observan buenos resultados para categorías cuyo vocabulario es muy distintivo (por ejemplo, “sci.space”, “autos”, “religión”), y peores resultados en categorías más difusas.\n",
        "La performance es sensible a textos cortos o con vocabulario poco representativo.\n",
        "Este enfoque demuestra que es posible clasificar sin entrenar un modelo supervisado, usando solo medidas de similaridad léxica. Más allá de esto, el desempeño es limitado por no\n",
        "aprovechar la distribución estadística global del vocabulario.\n",
        "\n",
        "**3. Entrenamiento de Naïve Bayes (Multinomial y ComplementNB)**\n",
        "\n",
        "**Observaciones**\n",
        "\n",
        "Al comparar MultinomialNB y ComplementNB, este último tiende a tener mejor desempeño, especialmente cuando las clases que presentan desbalanceos. La optimización de hiperparámetros del vectorizador (p. ej., min_df, max_df, use_idf, sublinear_tf) impacta fuertemente en los resultados.\n",
        "El f1-macro mejora significativamente respecto al modelo por prototipos, mostrando que el aprendizaje estadístico captura mejor los patrones globales del corpus.\n",
        "Los modelos Naïve Bayes demuestran por qué siguen siendo baseline competitivos en PNL tradicional.\n",
        "El hecho de mantener ngram_range fijo permite observar que el mayor impacto viene de los parámetros del vectorizador y del algoritmo, reforzando la importancia de la ingeniería de características.\n",
        "\n",
        "**4. Similaridad entre palabras (matriz transpuesta: término-documento)**\n",
        "\n",
        "**Observaciones**\n",
        "\n",
        "Al transponer la matriz, cada palabra queda representada por un vector que refleja su distribución en los documentos.\n",
        "Las palabras cercanas según similaridad suelen compartir contextos temáticos, aun cuando no aparezcan juntas en los mismos documentos.\n",
        "Los 5 términos seleccionados manualmente muestran clusters interpretables.\n",
        "El enfoque término-documento permite observar la estructura latente del vocabulario del corpus, más allá de co-ocurrencias directas."
      ],
      "metadata": {
        "id": "dXolZktUgNep"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vj3eej4ceZEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}