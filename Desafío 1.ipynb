{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf88ac8-5957-4bc8-9d36-e1b3b08073d7",
   "metadata": {},
   "source": [
    "## **Desafío 1 — Solución paso a paso (20 Newsgroups, TF‑IDF, Similaridad y Naïve Bayes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a1c6bd-0566-4f81-b00a-90af7954c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q scikit-learn numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a2e842-3dff-41e4-8093-b3322d503b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def top_k_indices(a, k):\n",
    "    \"\"\"Return indices of the top-k values of a 1D array (descending).\"\"\"\n",
    "    idx = np.argpartition(-a, kth=min(k, len(a)-1))[:k]\n",
    "    return idx[np.argsort(-a[idx])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc87b8-ac76-4ab9-a661-331362f6ac84",
   "metadata": {},
   "source": [
    "## **1) Carga del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135598ee-3de4-4573-953f-f9a75ca24b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: 20\n",
      "Ejemplo de documento (train[0]):\n",
      "\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail. ...\n"
     ]
    }
   ],
   "source": [
    "train = fetch_20newsgroups(subset='train', remove=('headers','footers','quotes'))\n",
    "test  = fetch_20newsgroups(subset='test',  remove=('headers','footers','quotes'))\n",
    "\n",
    "print(f\"Clases: {len(train.target_names)}\")\n",
    "print(\"Ejemplo de documento (train[0]):\\n\")\n",
    "print(train.data[0][:800], \"...\")  # vista parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c47da-c6a8-429b-badd-8cf3fabe144a",
   "metadata": {},
   "source": [
    "## **2) Vectorización con TF‑IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f7fd08-0b37-426c-8e11-5c328817f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 28764), (7532, 28764))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',      \n",
    "    max_df=0.5,                \n",
    "    min_df=5,                  \n",
    "    ngram_range=(1,2),        \n",
    "    sublinear_tf=True          \n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train.data)\n",
    "X_test  = tfidf.transform(test.data)\n",
    "\n",
    "y_train = train.target\n",
    "y_test  = test.target\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9c485-9567-46e1-a082-a2a8502f5a8c",
   "metadata": {},
   "source": [
    "## 3) **Ejercicio 1** — Similaridad coseno entre documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e9d241-39bc-4190-92bc-79ab5af79821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento de test #0 — clase real: rec.autos\n",
      "\n",
      "I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy. ...\n",
      "\n",
      "Top-5 documentos más similares en train:\n",
      " 1. idx= 4143 | clase=comp.sys.mac.hardware | cos=0.2385\n",
      " 2. idx=  401 | clase=rec.sport.hockey | cos=0.1562\n",
      " 3. idx= 6769 | clase=comp.sys.mac.hardware | cos=0.1550\n",
      " 4. idx= 4373 | clase=rec.autos | cos=0.1210\n",
      " 5. idx=10179 | clase=rec.autos | cos=0.1181\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "i_test = 0  # podés cambiar el índice para explorar distintos documentos\n",
    "\n",
    "# Similaridad coseno de un doc de test contra toda la matriz de train\n",
    "# (1 x n_train) @ (n_train x d)^T ya está implícito en cosine_similarity\n",
    "sims = cosine_similarity(X_test[i_test], X_train).ravel()\n",
    "topk = top_k_indices(sims, k)\n",
    "\n",
    "print(f\"Documento de test #{i_test} — clase real: {test.target_names[y_test[i_test]]}\\n\")\n",
    "print(test.data[i_test][:500], \"...\\n\")\n",
    "\n",
    "print(f\"Top-{k} documentos más similares en train:\")\n",
    "for rank, j in enumerate(topk, start=1):\n",
    "    print(f\"{rank:>2}. idx={j:>5} | clase={train.target_names[y_train[j]]} | cos={sims[j]:.4f}\")\n",
    "    # Si querés ver el texto:\n",
    "    # print(train.data[j][:200], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2502494-0105-4b19-9e29-00e38c1a033f",
   "metadata": {},
   "source": [
    "## 4) **Ejercicio 2** — Clasificador por prototipo (1‑NN por coseno) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b97ea7a-49b0-4a7b-95c3-874205e94bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro (1-NN coseno): 0.504\n"
     ]
    }
   ],
   "source": [
    "def predict_1nn_cosine(X_tr, y_tr, X_te, batch=256):\n",
    "    \"\"\"1-NN por coseno usando batches para ahorrar memoria.\"\"\"\n",
    "    y_pred = []\n",
    "    for start in range(0, X_te.shape[0], batch):\n",
    "        stop = min(start+batch, X_te.shape[0])\n",
    "        # (batch x d) vs (n_train x d) -> (batch x n_train)\n",
    "        S = cosine_similarity(X_te[start:stop], X_tr)\n",
    "        nn = S.argmax(axis=1)  # índice del train más similar\n",
    "        y_pred.append(y_tr[nn])\n",
    "    return np.concatenate(y_pred)\n",
    "\n",
    "yhat_1nn = predict_1nn_cosine(X_train, y_train, X_test, batch=128)\n",
    "f1_1nn = f1_score(y_test, yhat_1nn, average='macro')\n",
    "print(f\"F1-macro (1-NN coseno): {f1_1nn:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed05b65a-a946-45aa-a987-e58bf3529a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro (5-NN coseno): 0.572\n"
     ]
    }
   ],
   "source": [
    "def predict_knn_cosine(X_tr, y_tr, X_te, k=5, batch=128):\n",
    "    y_pred = []\n",
    "    for start in range(0, X_te.shape[0], batch):\n",
    "        stop = min(start+batch, X_te.shape[0])\n",
    "        S = cosine_similarity(X_te[start:stop], X_tr)\n",
    "        topk = np.argpartition(-S, kth=min(k, S.shape[1]-1), axis=1)[:, :k]\n",
    "        # ordenar cada fila según similitud descendente\n",
    "        rows = np.arange(topk.shape[0])[:, None]\n",
    "        sorted_topk = topk[rows, np.argsort(-S[rows, topk])]\n",
    "        # voto mayoritario\n",
    "        blk_pred = []\n",
    "        for r in range(sorted_topk.shape[0]):\n",
    "            labels = y_tr[sorted_topk[r]]\n",
    "            # empate: elegimos la clase con mayor suma de similitudes\n",
    "            if k > 1:\n",
    "                uniq, counts = np.unique(labels, return_counts=True)\n",
    "                if counts.max() == 1:  # todos distintos: desempatar por suma de similitudes\n",
    "                    sim_sums = {c: S[r, sorted_topk[r][labels==c]].sum() for c in uniq}\n",
    "                    blk_pred.append(max(sim_sums, key=sim_sums.get))\n",
    "                else:\n",
    "                    blk_pred.append(uniq[counts.argmax()])\n",
    "            else:\n",
    "                blk_pred.append(labels[0])\n",
    "        y_pred.extend(blk_pred)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "yhat_knn = predict_knn_cosine(X_train, y_train, X_test, k=5, batch=96)\n",
    "f1_knn = f1_score(y_test, yhat_knn, average='macro')\n",
    "print(f\"F1-macro (5-NN coseno): {f1_knn:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c461e-d7e2-4440-a58c-05c90521e173",
   "metadata": {},
   "source": [
    "## 5) **Ejercicio 3** — Naïve Bayes (Multinomial & Complement). Pruebo dos modelos: **MultinomialNB** y **ComplementNB**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d289d774-664a-4f03-8409-ac7009db3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores resultados:\n",
      "  MultinomialNB -> F1-macro=0.674 con alpha=0.1\n",
      "  ComplementNB  -> F1-macro=0.690 con alpha=0.5\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 2.0],\n",
    "}\n",
    "\n",
    "best = {\"mnb\": (-1, None), \"cnb\": (-1, None)}  # (score, alpha)\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    alpha = params[\"alpha\"]\n",
    "    mnb = MultinomialNB(alpha=alpha)\n",
    "    mnb.fit(X_train, y_train)\n",
    "    yhat = mnb.predict(X_test)\n",
    "    f1 = f1_score(y_test, yhat, average='macro')\n",
    "    if f1 > best[\"mnb\"][0]:\n",
    "        best[\"mnb\"] = (f1, alpha)\n",
    "\n",
    "    cnb = ComplementNB(alpha=alpha)\n",
    "    cnb.fit(X_train, y_train)\n",
    "    yhat = cnb.predict(X_test)\n",
    "    f1 = f1_score(y_test, yhat, average='macro')\n",
    "    if f1 > best[\"cnb\"][0]:\n",
    "        best[\"cnb\"] = (f1, alpha)\n",
    "\n",
    "print(\"Mejores resultados:\")\n",
    "print(f\"  MultinomialNB -> F1-macro={best['mnb'][0]:.3f} con alpha={best['mnb'][1]}\")\n",
    "print(f\"  ComplementNB  -> F1-macro={best['cnb'][0]:.3f} con alpha={best['cnb'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f1e0fd7-57ce-4ba4-bef8-7ff7c4c12856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.61      0.43      0.50       319\n",
      "           comp.graphics       0.61      0.70      0.65       389\n",
      " comp.os.ms-windows.misc       0.68      0.55      0.61       394\n",
      "comp.sys.ibm.pc.hardware       0.64      0.70      0.67       392\n",
      "   comp.sys.mac.hardware       0.74      0.67      0.70       385\n",
      "          comp.windows.x       0.77      0.75      0.76       395\n",
      "            misc.forsale       0.79      0.77      0.78       390\n",
      "               rec.autos       0.75      0.73      0.74       396\n",
      "         rec.motorcycles       0.76      0.74      0.75       398\n",
      "      rec.sport.baseball       0.90      0.80      0.85       397\n",
      "        rec.sport.hockey       0.58      0.91      0.71       399\n",
      "               sci.crypt       0.80      0.72      0.76       396\n",
      "         sci.electronics       0.68      0.58      0.62       393\n",
      "                 sci.med       0.83      0.76      0.79       396\n",
      "               sci.space       0.77      0.77      0.77       394\n",
      "  soc.religion.christian       0.52      0.88      0.66       398\n",
      "      talk.politics.guns       0.56      0.73      0.63       364\n",
      "   talk.politics.mideast       0.81      0.79      0.80       376\n",
      "      talk.politics.misc       0.63      0.43      0.51       310\n",
      "      talk.religion.misc       0.55      0.13      0.21       251\n",
      "\n",
      "                accuracy                           0.69      7532\n",
      "               macro avg       0.70      0.68      0.67      7532\n",
      "            weighted avg       0.70      0.69      0.69      7532\n",
      "\n",
      "=== ComplementNB ===\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.31      0.44      0.36       319\n",
      "           comp.graphics       0.70      0.68      0.69       389\n",
      " comp.os.ms-windows.misc       0.67      0.60      0.63       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.69      0.67       392\n",
      "   comp.sys.mac.hardware       0.79      0.71      0.75       385\n",
      "          comp.windows.x       0.77      0.80      0.79       395\n",
      "            misc.forsale       0.76      0.80      0.78       390\n",
      "               rec.autos       0.81      0.71      0.76       396\n",
      "         rec.motorcycles       0.82      0.75      0.78       398\n",
      "      rec.sport.baseball       0.89      0.83      0.86       397\n",
      "        rec.sport.hockey       0.87      0.92      0.90       399\n",
      "               sci.crypt       0.80      0.78      0.79       396\n",
      "         sci.electronics       0.67      0.53      0.59       393\n",
      "                 sci.med       0.78      0.79      0.79       396\n",
      "               sci.space       0.79      0.79      0.79       394\n",
      "  soc.religion.christian       0.56      0.89      0.69       398\n",
      "      talk.politics.guns       0.58      0.73      0.65       364\n",
      "   talk.politics.mideast       0.78      0.85      0.81       376\n",
      "      talk.politics.misc       0.65      0.44      0.53       310\n",
      "      talk.religion.misc       0.45      0.12      0.19       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.71      0.69      0.69      7532\n",
      "            weighted avg       0.72      0.71      0.70      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos de nuevo con los mejores hiperparámetros y mostramos reporte de clasificación\n",
    "best_alpha_mnb = best['mnb'][1] if best['mnb'][1] is not None else 1.0\n",
    "best_alpha_cnb = best['cnb'][1] if best['cnb'][1] is not None else 1.0\n",
    "\n",
    "mnb = MultinomialNB(alpha=best_alpha_mnb).fit(X_train, y_train)\n",
    "cnb = ComplementNB(alpha=best_alpha_cnb).fit(X_train, y_train)\n",
    "\n",
    "print(\"=== MultinomialNB ===\")\n",
    "print(classification_report(y_test, mnb.predict(X_test), target_names=test.target_names, zero_division=0))\n",
    "\n",
    "print(\"=== ComplementNB ===\")\n",
    "print(classification_report(y_test, cnb.predict(X_test), target_names=test.target_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf45e3-ff82-4638-bb3a-2f9c8c96a837",
   "metadata": {},
   "source": [
    "## 6) **Ejercicio 4** — Similaridad entre palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96323cfb-987f-4c09-a70d-ca15bf980428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras semilla consideradas: ['space', 'hockey', 'windows', 'jesus', 'car']\n",
      "\n",
      "=== Vecinos de 'space' ===\n",
      "       space station  cos=0.3077\n",
      "           sci space  cos=0.2716\n",
      "                nasa  cos=0.2499\n",
      "       space shuttle  cos=0.2402\n",
      "             shuttle  cos=0.1993\n",
      "       space program  cos=0.1986\n",
      "              launch  cos=0.1814\n",
      "       space related  cos=0.1801\n",
      "          disk space  cos=0.1746\n",
      "          space news  cos=0.1742\n",
      "\n",
      "=== Vecinos de 'hockey' ===\n",
      "                 nhl  cos=0.2569\n",
      "      hockey players  cos=0.2558\n",
      "                ncaa  cos=0.2216\n",
      "      college hockey  cos=0.2210\n",
      "         hockey east  cos=0.2148\n",
      "       hockey league  cos=0.2042\n",
      "                game  cos=0.2028\n",
      "              league  cos=0.2007\n",
      "             players  cos=0.1928\n",
      "                 ice  cos=0.1893\n",
      "\n",
      "=== Vecinos de 'windows' ===\n",
      "                 dos  cos=0.3104\n",
      "          ms windows  cos=0.2835\n",
      "         dos windows  cos=0.2469\n",
      "          windows nt  cos=0.2465\n",
      "                  ms  cos=0.2325\n",
      "                file  cos=0.1990\n",
      "     windows windows  cos=0.1971\n",
      "           microsoft  cos=0.1968\n",
      "               files  cos=0.1954\n",
      "     windows version  cos=0.1830\n",
      "\n",
      "=== Vecinos de 'jesus' ===\n",
      "        jesus christ  cos=0.3993\n",
      "              christ  cos=0.3776\n",
      "                 god  cos=0.3098\n",
      "           jesus did  cos=0.2650\n",
      "           god jesus  cos=0.2602\n",
      "                 sin  cos=0.2563\n",
      "          jesus said  cos=0.2488\n",
      "         jesus jesus  cos=0.2484\n",
      "          christians  cos=0.2461\n",
      "           jesus god  cos=0.2228\n",
      "\n",
      "=== Vecinos de 'car' ===\n",
      "             new car  cos=0.2236\n",
      "          bought car  cos=0.2119\n",
      "                cars  cos=0.1968\n",
      "             car car  cos=0.1923\n",
      "            car like  cos=0.1908\n",
      "              dealer  cos=0.1836\n",
      "        car accident  cos=0.1706\n",
      "               civic  cos=0.1592\n",
      "         car drivers  cos=0.1578\n",
      "               owner  cos=0.1556\n"
     ]
    }
   ],
   "source": [
    "# Transponer: cada fila representa un término como vector de aparición en documentos\n",
    "X_td = X_train.T  # (vocab_size x n_docs)\n",
    "\n",
    "# Elegí palabras interpretables del dominio 20 Newsgroups:\n",
    "seed_words = [\"space\", \"hockey\", \"windows\", \"jesus\", \"car\"]\n",
    "\n",
    "# Filtrar solo las que existan en el vocabulario tras el preprocesado\n",
    "seed_words = [w for w in seed_words if w in feature_names]\n",
    "print(\"Palabras semilla consideradas:\", seed_words)\n",
    "\n",
    "def similar_terms_for(word, topn=10):\n",
    "    idx = np.where(feature_names == word)[0]\n",
    "    if len(idx) == 0:\n",
    "        return []\n",
    "    idx = idx[0]\n",
    "    sims = cosine_similarity(X_td[idx], X_td).ravel()\n",
    "    # evitamos el término idéntico (top-1)\n",
    "    order = top_k_indices(sims, topn+1)\n",
    "    order = [j for j in order if j != idx][:topn]\n",
    "    return [(feature_names[j], float(sims[j])) for j in order]\n",
    "\n",
    "for w in seed_words:\n",
    "    print(f\"\\n=== Vecinos de '{w}' ===\")\n",
    "    for term, s in similar_terms_for(w, topn=10):\n",
    "        print(f\"{term:>20s}  cos={s:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbeef1-f22b-4a4b-ae55-35743b47f177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
